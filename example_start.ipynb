{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  !pip install wget\n",
    "  #!pip install split-folders\n",
    "  import wget\n",
    "  import zipfile\n",
    "  #import split-folders\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense, Flatten, Normalization, Dropout, Conv2D, MaxPooling2D, RandomFlip, RandomRotation, RandomZoom, BatchNormalization, Activation, InputLayer\n",
    "from keras.models import Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Veggie Classification\n",
    "\n",
    "For this assignment you'll need to classify some images of vegetables. \n",
    "\n",
    "## Parts\n",
    "\n",
    "Please do two separate classifications:\n",
    "<ol>\n",
    "<li> First, create a model from scratch. \n",
    "<li> Use transfer learning to use a pretrained model of your choice, adapted to this data. \n",
    "</ol>\n",
    "\n",
    "There won't be an explicit evaluation of accuracy, but you should take some steps to make each model as accurate as you reasonably can, any tuning option is fair game. Along with that, please structure it into a notebook that is well structured and clear that explains what you did and found. Think about:\n",
    "<ul>\n",
    "<li> Sections and headings. \n",
    "<li> A description of the approach taken (e.g. what did you do to determine size, tune, evaluate, etc...)\n",
    "<li> Visualization of some important things such as a confusion matrix and maybe some images. \n",
    "<li> Results, mainly focused on the scoring of the test data. \n",
    "</ul>\n",
    "\n",
    "The descriptions and explainations should highlight the choices you made and why you made them. Figure up to about a page or so worth of text total, explain what happened but don't write an essay. \n",
    "\n",
    "## Deliverables\n",
    "\n",
    "Please sumbmit a link to your github, where everyhting is fully run with all the outputs showing on the page. As well, in the notebook please add some kind of switch controlled by a variable that will control if the notebook runs to train the model or to load the model in from weights - so I can download it and click run all, it will load the saved weights, and predict.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The code in the start of this notebook will download and unzip the dataset, and there is also a simple example of creating datasets. You can change the dataset bit to use a different approach if you'd like. The data is already split into train, validation, and test sets. Please treat the separate test set as the final test set, and don't use it for any training or validation. Each folder name is its own label.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Marking will be based on the following:\n",
    "<ul>\n",
    "<li> Models are cretaed, tuned, and effective at classifying the data: 40%\n",
    "<li> Descriptions and explanations of the approach taken: 20%\n",
    "<li> Code is well structured and clear: 20%\n",
    "</ul>\n",
    "\n",
    "Overall the marking is pretty simple and direct, walk through the process of predicting the veggies, explain what you did, and show the results. If you do that, it'll get a good mark.\n",
    "\n",
    "### Tips\n",
    "\n",
    "Some hints that may be helpful to keep in mind:\n",
    "<ul>\n",
    "<li> The data is pretty large, so you'll want to use datasets rather than load everything into memory. The Keras docs have a few examples of different ways to load image data, our examples showed image generators and the image from directory datasets.  \n",
    "<li> Be careful of batch size, you may hit the colab limits. \n",
    "<li> You'll want to use checkpoints so you can let it train and pick up where you left off.\n",
    "<li> When developing, using a smaller dataset sample is a good idea. These weights could also be saved and loaded to jump start training on the full data. \n",
    "<li>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Unzip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to plot loss\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "def plot_acc(history):\n",
    "  plt.plot(history.history['accuracy'], label='accuracy')\n",
    "  plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_custom(current, total, width=80):\n",
    "    print(\"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total))\n",
    "import wget\n",
    "import zipfile\n",
    "zip_name = \"train.zip\"\n",
    "\n",
    "url = \"https://jrssbcrsefilesnait.blob.core.windows.net/3950data1/vegetable_image_dataset.zip\"\n",
    "\n",
    "if not os.path.exists(zip_name):\n",
    "    wget.download(url, zip_name, bar=bar_custom)\n",
    "\n",
    "with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Datasets - you can change this if desired\n",
    "# ENSURE FILE PATHS MATCH CORRECTLY\n",
    "IMAGE_SIZE=(224,224)\n",
    "train_dir='Vegetable Images/train'\n",
    "val_dir='Vegetable Images/validation'\n",
    "batch_size = 16\n",
    "\n",
    "# Load training data\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BUFFER = 150 \n",
    "VAL_SPLIT = .2\n",
    "\n",
    "EPOCHS = 20\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\"logs/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_accuracy', verbose=2, save_best_only=False, save_weights_only=True, mode='max', save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback = tf.keras.callbacks.EarlyStopping(monitor=MONITOR, patience=BASE_PATIENCE, restore_best_weights=True, min_delta=MIN_DELTA, mode=MODE)\n",
    "#checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(WEIGHT_PATH + \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_accuracy', verbose=2, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Rescaling\n",
    "rescale = Rescaling(scale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPAIN = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "#train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.shuffle(buffer_size=BUFFER)\n",
    "train_ds = train_ds.prefetch(buffer_size=TPAIN)\n",
    "\n",
    "val_ds = val_ds.map(lambda x, y: (rescale(x), y))\n",
    "#val_ds = val_ds.batch(batch_size)\n",
    "val_ds = val_ds.prefetch(buffer_size=TPAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape=IMAGE_SIZE + (3,)\n",
    "#inputs = keras.Input(shape=input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the model architecture with padding\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(15, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_m1 = model.fit(\n",
    "      train_ds,\n",
    "      validation_data=val_ds,\n",
    "      epochs=EPOCHS,\n",
    "      callbacks=[checkpoint_callback]\n",
    "  )\n",
    "plot_loss(log_m1)\n",
    "plot_acc(log_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding=\"same\", input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding=\"same\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding=\"same\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding=\"same\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, kernel_regularizer=\"l2\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(.3),\n",
    "    tf.keras.layers.Dense(128, kernel_regularizer=\"l2\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(15, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "  #optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "  optimizer=\"rmsprop\",\n",
    "  #loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  loss=\"categorical_crossentropy\",\n",
    "  metrics=['accuracy']\n",
    "  )\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "log_m2 = model1.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "plot_loss(log_m1)\n",
    "plot_acc(log_m1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Best Models and Illustrate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir='Vegetable Images/test'\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size = IMAGE_SIZE,\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode:\n",
    "   WEIGHT_PATH = \"logs/\"\n",
    "\n",
    "\n",
    "   if os.path.exists(WEIGHT_PATH):# Check if weight files exist\n",
    "      list_of_files = glob.glob(os.path.join(WEIGHT_PATH, \"*.hdf5\"))# Get a list of all HDF5 files in the directory\n",
    "      list_of_files.sort(key=os.path.getctime, reverse=True)# Sort the list of files by creation time (latest file first)\n",
    "      if list_of_files:\n",
    "         latest_file = list_of_files[0]# Load the weights from the latest file\n",
    "         if latest_file:\n",
    "            model.load_weights(latest_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3950",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
